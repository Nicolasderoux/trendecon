---
title: "Creating long daily series"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Creating long daily series}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(trendecon)
```


## Intro

Google search results are available on a daily, weekly or monthly frequency. As with individual samples, querying Google at a different frequency will lead to substantially different results.

Our goal is to produce long daily time series, ideally from 2006. However, Google does not provide daily or weekly data for such a long time period. We circumvent the problem by applying a moving window of daily and weekly queries over the whole time period.

This vingette describes the production processes of trendecon. The production function start with `proc_` and usually operate on the file system. That means that calling this functions will write to your disk.


## Directory structure

The `proc_` functions write to the working directory. If you are unsure about your current working directory, use `getwd()`.

Within the working directory, the `proc_` functions assume the existence of two folders,

- `data`
- `raw`

which, if not present, are created when calling `proc_keyword_init` for the first time.

Within these folders, there is a subfolder for every `geo` location.
Thus, you may see the following subfolders

- `data/ch`
- `data/at`
- `raw/ch`
- `raw/at`

What is the difference between `data` and `raw`? In the `raw` folder, we collect all the data downloaded from Google, plus some transfromations, such as the seasonally adjusted or the combined series.

In the `data` folder, we collect our final indicators - the data you see on the website.


## Initial Download

To include a new series, each keyword must be initiated. Be careful, as this causes a lot of queries to Google.

```r
proc_keyword_init("Rezession", "CH")
```
After running we have the aggregated series at daily, weekly and monthly frequency, stored in the `raw` folder. In
 the example above, the files `raw/ch/Rezession_d.csv`, `raw/ch/Rezession_w.csv`, and `raw/ch/Rezession_m.csv` are
  created.

## Updating trendecon indicators

Trendecon includes a few functions that process a collection of keywords.
These functions produce the indicators that we show on trendecon.org. These are called by our automated process on
 GitHub, so they usually do not need to be called manually.

To process all Swiss indicators of trendecon, run:

```r
proc_trendecon_ch()
```

Once all the keywords are initiated, `proc_trendecon_ch()` updates the series for each keyword, and produces the
 indicators. In the final step, the data is copied to the data repository.

- [ ] TODO: what data exactly is copied?
- [ ] TODO: describe where the list of keywords which need to be initiated can be found.

While `proc_trendecon_ch()` automatically updates our indicators, it is insightful to walk through the different
 steps it performs, as these are the steps which are required to build indicators from other sets of keywords or for
  other countries.


### Scripts for each indicator

To construct each indicator, an indicator-specific script in the folder `inst/script` is called. For example

```r
source("inst/script/trendecon.R")
```

produces the indicator for economic sentiment. To do so, it first performs a number of steps for each keyword on
 which the indicator is based. For example, our main indicator is based on the keywords `"Wirtschaftskrise"`, `"Kurzarbeit
 "`, `"arbeitslos"`, and `"Insolvenz"`. Once the data for each keyword has been processed, the actual indicator is
  constructed from the individual keyword-series using a principal-component approach.

Below, we describe the steps which are performed for each of the keywords. All these steps are bundled together in
 the function `proc_keyword`.

#### Bundled steps for each keyword

For each keyword, `proc_keyword` is called, for example

```r
proc_keyword("Rezession", "CH")
```

which in turn performs the following steps.

##### Update data series with latest data
In the first step, the raw data series for each keyword are updated with the latest daily, weekly, and monthly data.
For example, to update the raw series for keyword `"Rezession"` for Switzerland, call

```r
proc_keyword_latest("Rezession", "CH")
```

- [ ] TODO: This will fail without proper error if `proc_keyword_init` has not been run.

##### Bending

To combine the three frequencies, we apply the following methodology: In a first step, we "bend" the daily series to the weekly values, by applying a variant of the Chow-Lin (1971) method. This preserves the movement of the daily series and ensures that weekly averages are identical to the original weekly series. We then use the same methodology to bend the series to the monhtly values.

To combine the three frequencies for a given keyword, use:

```r
proc_combine_freq("Rezession", "CH")
```

##### Seasonal Adjustment

- [ ] FXIME some text from the website

To seasonally adjust a combined keyword, use:

```r
proc_seas_adj("Rezession", "CH")
```

##### Reading and Writing

There are two special helper functions that are useful when working with production data:

- `read_keyword`
- `write_keyword`






