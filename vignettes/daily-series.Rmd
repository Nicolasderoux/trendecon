---
title: "Creating long daily series"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Creating long daily series}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Once the combination of useful keywords is selected we might want to use them as economic indicators in production and display them on [trendecon.org](https://www.trendecon.org/). This vignette describes the steps for adding new indicators to the production processes of "Trendecon".

## Directory structure ##

The names of production functions within the `trendecon` package start with `proc_`.
They usually operate on the file system which means that calling these functions will write files to the local disk.
The `proc_` functions will save files within two folders: `data` and `raw`, which are located under the working directory (`getwd()`).
`raw` folder holds all the data downloaded from Google, plus some transformations, such as seasonally adjusted or combined series.
`data` folder, on the other hand, collects the final indicators - the data displayed on the website.
If not present these folders will be created when calling `proc_keyword_init` for the first time.

Within these folders, every used `geo` location will have its own subfolder.
Thus, in the end, if we used Swiss and Austrian indicators, we would end up with the following directory structure:

```
│
├── data
│   ├── at
│   └── ch
│
└── raw
    ├── at
    └── ch
```


## Initial download ##

To include a new series, each keyword must first be initiated.
Our goal is to produce long daily time series, ideally ranging from 2006.
However, Google does not provide daily or weekly data for such a long time period.
Hence, we need to circumvent the problem by applying a moving window of daily and weekly queries over the whole time period.
So be careful, as this causes a lot of queries to Google.

```r
proc_keyword_init("Rezession", "CH")
```

After running the code above we will have the aggregated series at daily, weekly and monthly frequency, stored in the `raw` folder.
In this example the following files: `raw/ch/Rezession_d.csv`, `raw/ch/Rezession_w.csv`, and `raw/ch/Rezession_m.csv` will be created.


## Updating trendecon indicators ##

Once all the keywords are initiated and the raw data is obtained we need to process it.
`trendecon` includes a few functions that process a collection of keywords.
These functions produce the final indicators that we show on [trendecon.org](https://www.trendecon.org/).
These are called by an automated process which is set up on GitHub, so we do not need to call them manually when updating the data.

For example, in order to process all Swiss indicators of trendecon, run:

```r
proc_trendecon_ch()
```

This function updates the series for each keyword, and produces the indicators.
In the final step all the specified Swiss indicators will be processed and the final data is stored in the `data/ch` folder.
The list of active Swiss indicators can be found within the code of `proc_trendecon_ch()` function.


## Preprocessing indicators step by step  ##

While `proc_trendecon_ch()` automatically updates the indicators it cannot add new indicators to production.
In order to be able to introduce new indicators it is insightful to walk through the different steps performed by `proc_trendecon_ch()`.
The same steps will be required to build indicators from other sets of keywords or for other countries.
The steps of such preparation are outlined below.

### Step 1: update with latest data ###

In the first step, the raw data series for each keyword are updated with the latest daily, weekly, and monthly data.
For example, to update the raw series for keyword `"Rezession"` for Switzerland, the script calls the following internal function:

```r
proc_keyword_latest("Rezession", "CH")
```

This function downloads raw daily, weekly, and monthly data for the specified pair of keyword and geo location.
If the data for a particular keyword is not yet available, `proc_keyword_init()` should be called instead.

### Step 2: bending ###

To combine the three frequencies (monthly, weekly, and daily), we apply the following methodology: in a first step, we "bend" the daily series to the weekly values, by applying a variant of the Chow-Lin (1971) method.
This preserves the movement of the daily series and ensures that weekly averages are identical to the original weekly series.
We then use the same methodology to bend the series to the monthly values.

To combine the three frequencies for a given keyword, the script calls another internal function:

```r
proc_combine_freq("Rezession", "CH")
```

### Step 3: seasonal adjustment ###

Some keywords' time series might display seasonal patterns.
For example it is not surprising that searches for gardening are higher in spring.
In order to make meaningful comparisons over time such seasonal patterns, present within the data, need to be removed.
To achieve this `trendecon` uses the "Prophet" procedure for estimating an additive model where non-linear trends are fit with yearly and weekly seasonality and the holiday effects.

To seasonally adjust a combined keyword, the script calls the following internal function:

```r
proc_seas_adj("Rezession", "CH")
```

### Step 4: combining ###

Once the raw data for each keyword has been processed we end up with multiple time series - one for each keyword within the indicator.
As an example the main indicator uses the following keywords: `"Wirtschaftskrise"`, `"Kurzarbeit "`, `"arbeitslos"`, and `"Insolvenz"`.
To turn several provided keywords into a single time series the first principal component is used.

In order to achieve this the script calls `ts_prcomp()` function from the `tsbox` package.

### Step 5: writing the data ###

Finally the prepared index is saved to a file in the data folder:

```
write_keyword(prepared_data, "indicator", "CH")
```
