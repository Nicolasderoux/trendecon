---
title: "Creating long daily series"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Creating long daily series}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(trendecon)
```


## Intro

Google search results are available on a daily, weekly or monthly frequency. As with individual samples, querying Google at a different frequency will lead to substantially different results.

Our goal is to produce long daily time series, ideally from 2006. However, Google does not provide daily or weekly data for such a long time period. We circumvent the problem by applying a moving window of daily and weekly queries over the whole time period.

This vingette describes the production processes of trendecon. The production function start with `proc_` and usually operate on the file system. That means that calling this functions will write to your disk.


## Directory structure

The `proc_` functions write to the working directory. If you are unsure about your current working directory, use `getwd()`.

Within the working directory, the `proc_` functions assume two folders:

- `data`
- `raw`

Within these folders, there is a subfolder for every `geo` location.
Thus, you may see the following subfolders

- `data/ch`
- `data/at`
- `raw/ch`
- `raw/at`

What is the difference between `data` and `raw`? In the `raw` folder, we collect all the data downloaded from Google, plus some transfromations, such as the seasonally adjusted or the combined series.

In the `data` folder, we collect our final indicators - the data you see on the website.


## Initial Download

To include a new series, each keyword must be initiated. Be careful, as this causes a lot of queries to Google.

```r
proc_keyword_init("Rezession", "DE")
```

In this example, the files `raw/de/Rezession_d.csv`, `raw/de/Rezession_m.csv`, and `raw/de/Rezession_w.csv` are created.

## Daily Download

Once all the keywords are initiated, the script updates the series and produces the indicator. The last line copies the data to the data repository.

Q: which script?

```r
proc_keyword_latest("Rezession", "DE")
```

After running we have the aggregated series at all three frequencies, stored in the `raw` folder.

Q: Previously, proc_keyword_latest would save files with suffixes. Now it seems to update the raw files instead? (At
 least the daily file). How is that done?

## Bending

To combine the three frequencies, we apply the following methodology: In a first step, we "bend" the daily series to the weekly values, by applying a variant of the Chow-Lin (1971) method. This preserves the movement of the daily series and ensures that weekly averages are identical to the original weekly series. We then use the same methodology to bend the series to the monhtly values.

To combine the three frquencies for a given keyword, use:

```r
proc_combine_freq("Rezession", "DE")
```

## Seasonal Adjustment

FXIME some text from the website

To seasonally adjust a combined keyword, use:

```r
proc_seas_adj("Rezession", "DE")
```


## Combining Downloading, Bending, seasonal adjustments.

In the daily update process, it is sufficient to run:

```r
proc_keyword("Rezession", "DE")
```

Which combines all the three steps above.



## Reading and Writing

There are two special helper functions that are useful when working with production data:

- `read_keyword`
- `write_keyword`


## Updating trendecon indicators

Trendecon includes a few functions that process a collection of keywords.
These are the ones that we show on trendecon.org. These are called by our automtated processed on GitHub, so they usually don't need to be called manually.

To process all swiss indicators of trendecon, run:

```r
proc_trendecon_ch
```







